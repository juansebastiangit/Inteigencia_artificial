{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\n\n# Seed para que las redes con iguales parametros no generen resultados aleatorios y tener repetibilidad\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Para las graficas importamos matplotlib\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n#Función para plotear\ndef plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n\n    \n#Traemos los datos de Fashion MNIST\n(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\nX_train_full_normalized = X_train_full.astype(np.float32) / 255\nX_test = X_test.astype(np.float32) / 255\nX_train, X_valid = X_train_full_normalized[:-5000], X_train_full_normalized[-5000:]\ny_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-28T19:19:43.828629Z","iopub.execute_input":"2024-09-28T19:19:43.829034Z","iopub.status.idle":"2024-09-28T19:19:58.539157Z","shell.execute_reply.started":"2024-09-28T19:19:43.828981Z","shell.execute_reply":"2024-09-28T19:19:58.538237Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#definimos la operacion kernel como un kernel gaussiano\n\ndef rbf_kernel(X, Y, sigma=1.0):\n    X_expanded = tf.expand_dims(X, axis=1)  # Shape: (batch_size, 1, latent_dim)\n    Y_expanded = tf.expand_dims(Y, axis=0)  # Shape: (1, batch_size, latent_dim)\n    squared_distance = tf.reduce_sum(tf.square(X_expanded - Y_expanded), axis=2)\n    return tf.exp(-squared_distance / (2 * sigma ** 2))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T19:20:54.002302Z","iopub.execute_input":"2024-09-28T19:20:54.003451Z","iopub.status.idle":"2024-09-28T19:20:54.009189Z","shell.execute_reply.started":"2024-09-28T19:20:54.003402Z","shell.execute_reply":"2024-09-28T19:20:54.007986Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Debemos definir la funcion de costo\ndef COCO_loss(alpha,x_true,x_pred,y_true,y_pred,beta=1.0,eta=0.5,gamma=0.5):\n    K=rbf_kernel(x_true,x_pred)\n    L=rbf_kernel(y_true,y_pred)\n    loss = (-tf.reduce_mean(alpha*K*L*beta))+((eta/2)*tf.reduce_sum(alpha*K*alpha)-1)+((gamma/2)*tf.reduce_sum(beta*L*beta)-1)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-09-28T19:21:32.307242Z","iopub.execute_input":"2024-09-28T19:21:32.307603Z","iopub.status.idle":"2024-09-28T19:21:32.314140Z","shell.execute_reply.started":"2024-09-28T19:21:32.307569Z","shell.execute_reply":"2024-09-28T19:21:32.312850Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Número de clases para clasificar y batch size\nclass_num=10\nbatch=64\n\n#Definimos una red que va a recosntruir y clasificar las imagenes de fashion mnist\n#La primera sección se compone de las capas convolucionales que van a extraer las caracteristicas de las imagenes\ninput_layer = keras.layers.Input(shape=[28,28])\nx = keras.layers.Reshape([28,28,1])(input_layer)\nx = keras.layers.Conv2D(16, name=\"Conv1\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.MaxPool2D(pool_size=2)(x)\nx = keras.layers.Conv2D(32,name=\"Conv2\", kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2D(32, name=\"Conv3\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.MaxPool2D(pool_size=2)(x)\nx = keras.layers.Conv2D(64, name=\"Conv4\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2D(64, name=\"Conv5\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nalpha = keras.layers.Dense(1,activation=\"relu\")(x)\nlatent_space = keras.layers.MaxPool2D(pool_size=2)(x)\n#A partir de este punto siguen las capas densas que utilizan las caracteristicas extraidas para definir a que clase\n#pertenecen las imagenes\nclass_input = keras.layers.Flatten()(latent_space)\nx = keras.layers.Dense(500,name=\"First_class_layer\",activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(class_input)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(200,activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(100,activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nclass_output = keras.layers.Dense(class_num,activation=\"softmax\",name=\"class_output\")(x)\n#Tambien añadimos una seccion de reconstruccion para regularizar\ndecoder_input = keras.layers.Conv2DTranspose(32,name=\"Convtrans1\", kernel_size=3, strides=2, padding=\"VALID\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.01))(latent_space)\nx = keras.layers.Dropout(rate=0.1)(decoder_input)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2DTranspose(16,name=\"Convtrans2\", kernel_size=3, strides=2, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.01))(x)\nx = keras.layers.Dropout(rate=0.1)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2DTranspose(1,name=\"Convtrans3\", kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\")(x)\ndecoder_output = keras.layers.Reshape([28, 28],name=\"reconstruction_output\")(x)\n\n#Definimos el modelo usando la api funcional y lo compilamos, al final mostramos el resumen del modelo o un diagrama \nclassifier = keras.Model(inputs=input_layer,outputs=[alpha,class_output,decoder_output])\n#Creamos el objeto loss\nCOCO = COCO_loss(alpha,x_true,x_pred,y_true,y_pred)#Posiblemente toque revisarlo o en un loop de entrenamiento custom, o con add_loss que no se como se\n                                                #revisa\nclassifier.compile(loss=[COCO,\"sparse_categorical_crossentropy\",\"binary_crossentropy\"],optimizer=keras.optimizers.Adam(0.0001),metrics=[\"sparse_categorical_accuracy\",\"accuracy\"])\nclassifier.summary()","metadata":{"execution":{"iopub.status.busy":"2024-09-28T19:21:47.456213Z","iopub.execute_input":"2024-09-28T19:21:47.456926Z","iopub.status.idle":"2024-09-28T19:21:47.758651Z","shell.execute_reply.started":"2024-09-28T19:21:47.456879Z","shell.execute_reply":"2024-09-28T19:21:47.757332Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m classifier \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minput_layer,outputs\u001b[38;5;241m=\u001b[39m[alpha,class_output,decoder_output])\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#Creamos el objeto loss\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m COCO \u001b[38;5;241m=\u001b[39m COCO_loss(alpha,\u001b[43mx_true\u001b[49m,x_pred,y_true,y_pred)\n\u001b[1;32m     55\u001b[0m classifier\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m[COCO,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m],optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.0001\u001b[39m),metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     56\u001b[0m classifier\u001b[38;5;241m.\u001b[39msummary()\n","\u001b[0;31mNameError\u001b[0m: name 'x_true' is not defined"],"ename":"NameError","evalue":"name 'x_true' is not defined","output_type":"error"}]},{"cell_type":"code","source":"#Se entrena el modelo\nhistory = classifier.fit(X_train,[y_train,X_train], batch,epochs=200,\n                      validation_data=(X_valid,[y_valid,X_valid]))","metadata":{},"execution_count":null,"outputs":[]}]}