{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sklearn\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\n\n# Seed para que las redes con iguales parametros no generen resultados aleatorios y tener repetibilidad\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Para las graficas importamos matplotlib\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n#Función para plotear\ndef plot_image(image):\n    plt.imshow(image, cmap=\"binary\")\n    plt.axis(\"off\")\n\n    \n#Traemos los datos de Fashion MNIST\n(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\nX_train_full_normalized = X_train_full.astype(np.float32) / 255\nX_test = X_test.astype(np.float32) / 255\nX_train, X_valid = X_train_full_normalized[:-5000], X_train_full_normalized[-5000:]\ny_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#definimos la operacion kernel como un kernel gaussiano\n\ndef rbf_kernel(X, Y, sigma=1.0):\n    X_expanded = tf.expand_dims(X, axis=1)  # Shape: (batch_size, 1, latent_dim)\n    Y_expanded = tf.expand_dims(Y, axis=0)  # Shape: (1, batch_size, latent_dim)\n    squared_distance = tf.reduce_sum(tf.square(X_expanded - Y_expanded), axis=2)\n    return tf.exp(-squared_distance / (2 * sigma ** 2))\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Debemos definir la funcion de costo\ndef COCO_loss(alpha,batch_size,x_true,x_pred,y_true,y_pred,beta=1.0,eta=0.5,gamma=0.5):\n    K=rbf_kernel(x_true,x_pred)\n    L=rbf_kernel(y_true,y_pred)\n    loss = (-(1/batch_size)*alpha*K*L*beta)+((eta/2)*alpha*K*alpha-1)+((gamma/2)*beta*L*beta-1)\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Número de clases para clasificar y batch size\nclass_num=10\nbatch=64\n\n#Definimos una red que va a recosntruir y clasificar las imagenes de fashion mnist\n#La primera sección se compone de las capas convolucionales que van a extraer las caracteristicas de las imagenes\ninput_layer = keras.layers.Input(shape=[28,28])\nx = keras.layers.Reshape([28,28,1])(input_layer)\nx = keras.layers.Conv2D(16, name=\"Conv1\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.MaxPool2D(pool_size=2)(x)\nx = keras.layers.Conv2D(32,name=\"Conv2\", kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2D(32, name=\"Conv3\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.MaxPool2D(pool_size=2)(x)\nx = keras.layers.Conv2D(64, name=\"Conv4\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2D(64, name=\"Conv5\",kernel_size=3, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nalpha = keras,layers.Dense(1,activation=\"relu\")(x)\nlatent_space = keras.layers.MaxPool2D(pool_size=2)(x)\n#A partir de este punto siguen las capas densas que utilizan las caracteristicas extraidas para definir a que clase\n#pertenecen las imagenes\nclass_input = keras.layers.Flatten()(latent_space)\nx = keras.layers.Dense(500,name=\"First_class_layer\",activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(class_input)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(200,activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Dense(100,activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.04))(x)\nx = keras.layers.Dropout(rate=0.25)(x)\nx = keras.layers.BatchNormalization()(x)\nclass_output = keras.layers.Dense(class_num,activation=\"softmax\",name=\"class_output\")(x)\n#Tambien añadimos una seccion de reconstruccion para regularizar\ndecoder_input = keras.layers.Conv2DTranspose(32,name=\"Convtrans1\", kernel_size=3, strides=2, padding=\"VALID\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.01))(latent_space)\nx = keras.layers.Dropout(rate=0.1)(decoder_input)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2DTranspose(16,name=\"Convtrans2\", kernel_size=3, strides=2, padding=\"SAME\", activation=\"relu\",kernel_initializer=\"HeNormal\",kernel_regularizer=keras.regularizers.l2(0.01))(x)\nx = keras.layers.Dropout(rate=0.1)(x)\nx = keras.layers.BatchNormalization()(x)\nx = keras.layers.Conv2DTranspose(1,name=\"Convtrans3\", kernel_size=3, strides=2, padding=\"SAME\", activation=\"sigmoid\")(x)\ndecoder_output = keras.layers.Reshape([28, 28],name=\"reconstruction_output\")(x)\n\n#Definimos el modelo usando la api funcional y lo compilamos, al final mostramos el resumen del modelo o un diagrama \nclassifier = keras.Model(inputs=input_layer,outputs=[class_output,decoder_output])\n#Creamos el objeto loss\nCOCO = COCO_loss(alpha,batch,x_true,x_pred,y_true,y_pred)\nclassifier.compile(loss=[\"sparse_categorical_crossentropy\",\"binary_crossentropy\"],optimizer=keras.optimizers.Adam(0.0001),metrics=[\"sparse_categorical_accuracy\",\"accuracy\"])\nclassifier.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Se entrena el modelo\nhistory = classifier.fit(X_train,[y_train,X_train], batch,epochs=200,\n                      validation_data=(X_valid,[y_valid,X_valid]))","metadata":{},"execution_count":null,"outputs":[]}]}