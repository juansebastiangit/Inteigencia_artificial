{"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/amalvarezme/AprendizajeMaquina/blob/main/7_TopicosAvanzados/4_DKernelsEmbeddings/4_GPFlow_GaussianProcess.ipynb","timestamp":1724944930873}]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Ejercicio 1**\n# Descripción de los modelos GP","metadata":{}},{"cell_type":"markdown","source":"# GPR ","metadata":{}},{"cell_type":"markdown","source":"# GPC","metadata":{}},{"cell_type":"markdown","source":"# VGP","metadata":{}},{"cell_type":"markdown","source":"# SGPR","metadata":{}},{"cell_type":"markdown","source":"# SVGP","metadata":{}},{"cell_type":"markdown","source":"# **Ejercicio 2**\n# Descripción de la optimización por tensorflow y scipy","metadata":{}},{"cell_type":"markdown","source":"# **Ejercicio 3**\n# Clasificador multiclase con SVGP","metadata":{}},{"cell_type":"markdown","source":"**Instalamos la libreria de GPFlow**","metadata":{}},{"cell_type":"code","source":"!pip install gpflow --upgrade #tensorflow~=2.12.0 tensorflow-probability~=0.20.0","metadata":{"id":"DPmEpdmN3BXv","outputId":"26436efd-4f42-4fe8-e9a2-f07cdd5c928e","execution":{"iopub.status.busy":"2024-10-03T00:27:55.253955Z","iopub.execute_input":"2024-10-03T00:27:55.254803Z","iopub.status.idle":"2024-10-03T00:28:08.266758Z","shell.execute_reply.started":"2024-10-03T00:27:55.254762Z","shell.execute_reply":"2024-10-03T00:28:08.265602Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: gpflow in /opt/conda/lib/python3.10/site-packages (2.9.2)\nRequirement already satisfied: check-shapes>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from gpflow) (1.1.1)\nRequirement already satisfied: deprecated in /opt/conda/lib/python3.10/site-packages (from gpflow) (1.2.14)\nRequirement already satisfied: multipledispatch>=0.6 in /opt/conda/lib/python3.10/site-packages (from gpflow) (1.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from gpflow) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gpflow) (21.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from gpflow) (1.14.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from gpflow) (70.0.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from gpflow) (0.9.0)\nRequirement already satisfied: tensorflow-probability>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability[tf]>=0.12.0->gpflow) (0.24.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from gpflow) (4.12.2)\nRequirement already satisfied: tensorflow>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from gpflow) (2.16.1)\nRequirement already satisfied: dropstackframe>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from check-shapes>=1.0.0->gpflow) (0.1.1)\nRequirement already satisfied: lark<2.0.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from check-shapes>=1.0.0->gpflow) (1.2.2)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (2.32.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (2.4.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.4.0->gpflow) (0.37.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.12.0->tensorflow-probability[tf]>=0.12.0->gpflow) (5.1.1)\nRequirement already satisfied: cloudpickle>=1.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.12.0->tensorflow-probability[tf]>=0.12.0->gpflow) (3.0.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability>=0.12.0->tensorflow-probability[tf]>=0.12.0->gpflow) (0.1.8)\nRequirement already satisfied: tf-keras>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow-probability[tf]>=0.12.0->gpflow) (2.16.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->gpflow) (3.1.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.4.0->gpflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow>=2.4.0->gpflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow>=2.4.0->gpflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow>=2.4.0->gpflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.4.0->gpflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.4.0->gpflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.4.0->gpflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow>=2.4.0->gpflow) (2024.7.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.4.0->gpflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.4.0->gpflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow>=2.4.0->gpflow) (3.0.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow>=2.4.0->gpflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow>=2.4.0->gpflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow>=2.4.0->gpflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow>=2.4.0->gpflow) (0.1.2)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Importamos paquetes, definimos funciones y llamamos los datos de FashionMNIST**","metadata":{}},{"cell_type":"code","source":"import gpflow\nfrom gpflow.ci_utils import reduce_in_tests\nfrom gpflow.utilities import print_summary, set_trainable\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport pandas as pd\n\n# Seed para que las redes con iguales parametros no generen resultados aleatorios y tener repetibilidad\nnp.random.seed(42)\ntf.random.set_seed(42)\n\n# Para las graficas importamos matplotlib\n%matplotlib inline\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nmpl.rc('axes', labelsize=14)\nmpl.rc('xtick', labelsize=12)\nmpl.rc('ytick', labelsize=12)\n\n    \n#Traemos los datos de Fashion MNIST\n(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\nX_train_full_normalized = X_train_full.astype(np.float32) / 255\nX_test = X_test.astype(np.float32) / 255\nX_train, X_valid = X_train_full_normalized[:-5000], X_train_full_normalized[-5000:]\ny_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n","metadata":{"id":"7t2z0d1H4l3P","execution":{"iopub.status.busy":"2024-10-03T00:28:16.926846Z","iopub.execute_input":"2024-10-03T00:28:16.927535Z","iopub.status.idle":"2024-10-03T00:28:18.158734Z","shell.execute_reply.started":"2024-10-03T00:28:16.927491Z","shell.execute_reply":"2024-10-03T00:28:18.157707Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tf.__version__)\nprint(gpflow.__version__)","metadata":{"id":"Jw2uNI5A4uAE","outputId":"bf996999-184b-469c-d3fd-0b521af96bd5","execution":{"iopub.status.busy":"2024-10-03T00:28:20.983876Z","iopub.execute_input":"2024-10-03T00:28:20.984276Z","iopub.status.idle":"2024-10-03T00:28:20.989148Z","shell.execute_reply.started":"2024-10-03T00:28:20.984237Z","shell.execute_reply":"2024-10-03T00:28:20.988315Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"2.16.1\n2.9.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Debido a las limitaciones de los GPs con conjuntos de datos grandes, tomamos solo los primeros 10000 datos del conjunto de entrenamiento de FashionMNIST**","metadata":{}},{"cell_type":"code","source":"x_train=X_train[:10000]\ny_train=y_train[:10000]\nprint(x_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:28:23.113440Z","iopub.execute_input":"2024-10-03T00:28:23.114201Z","iopub.status.idle":"2024-10-03T00:28:23.119256Z","shell.execute_reply.started":"2024-10-03T00:28:23.114163Z","shell.execute_reply":"2024-10-03T00:28:23.118314Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(10000, 28, 28)\n(10000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Para poder entrenar el modelo, es necesario aplanar las imagenes de 28x28 a una sola dimension de 784, y para evitar errores de tipo pasamos todos los datos a float64**","metadata":{}},{"cell_type":"code","source":"x_train_f = x_train.reshape(-1,28*28)\nprint(x_train_f.shape)\ny_train_f=y_train.reshape(-1,1)\nprint(y_train_f.shape)\nx_train_64 = x_train_f.astype(np.float64)\ny_train_64 = y_train_f.astype(np.float64)\ndata_train=(x_train_64,y_train_64)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:28:28.219814Z","iopub.execute_input":"2024-10-03T00:28:28.220210Z","iopub.status.idle":"2024-10-03T00:28:28.243470Z","shell.execute_reply.started":"2024-10-03T00:28:28.220173Z","shell.execute_reply":"2024-10-03T00:28:28.242435Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"(10000, 784)\n(10000, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**De forma similar, vamos a verificar las predicciones solo con 1000 datos del conjunto de prueba de FashionMNIST**","metadata":{}},{"cell_type":"code","source":"x_test = X_test[:1000]\ny_test=y_test[:1000]\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:28:37.685796Z","iopub.execute_input":"2024-10-03T00:28:37.686204Z","iopub.status.idle":"2024-10-03T00:28:37.691923Z","shell.execute_reply.started":"2024-10-03T00:28:37.686167Z","shell.execute_reply":"2024-10-03T00:28:37.690963Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"(1000, 28, 28)\n(1000,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Y aplanamos estas imagenes también, asi como las convertimos a float64**","metadata":{}},{"cell_type":"code","source":"x_test_f = x_test.reshape(-1,28*28)\nprint(x_test_f.shape)\ny_test_f=y_test.reshape(-1,1)\nprint(y_test_f.shape)\nx_test_64 = x_test_f.astype(np.float64)\ny_test_64 = y_test_f.astype(np.float64)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:28:44.458728Z","iopub.execute_input":"2024-10-03T00:28:44.459123Z","iopub.status.idle":"2024-10-03T00:28:44.465990Z","shell.execute_reply.started":"2024-10-03T00:28:44.459086Z","shell.execute_reply":"2024-10-03T00:28:44.464870Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"(1000, 784)\n(1000, 1)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Definimos el modelo usando los kernels, el liklihood multiclase y el modelo sparse variational de gpflow**","metadata":{}},{"cell_type":"code","source":"#Definmos los kernels a usar, el kernel Matern32 es estandar para la aplicacion de clasificacion, y el white añade ruido gausiano fijo\nkernel = gpflow.kernels.Matern32() + gpflow.kernels.White(variance=0.01) \n\n#Definimos el numero de clases para clasificar, FashionMNIST tiene 10\nC = 10\n\n# Definimos el liklihood y la funcion para mapear las salidas latentes del GP a las probabilidades de clase (invlink)\n# Robustmax se usa para asegurar que las probabilidades nunca sean 1 o 0, evitando problemas de confianza exagerada o asturación. \n# Tambien ayuda a modelar mejor la incertidumbre o varianza\ninvlink = gpflow.likelihoods.RobustMax(C)  \nlikelihood = gpflow.likelihoods.MultiClass(#El liklihood Multiclass es el estandar de GPFlow para clasificacon multiclase\n    C, invlink=invlink\n) \nZ = x_train_64[::5].copy()  # Se definen los puntos inducidos para manejar el problema del costo computacional\n#Z trata de representar el conjunto total de datos con menos información para que sea más facil resolver el GP al invertir las matrices\n\n#Llamamos todo lo definido anteriormente para definir el modelo m\nm = gpflow.models.SVGP(\n    kernel=kernel,\n    likelihood=likelihood,\n    inducing_variable=Z,\n    num_latent_gps=C,#tenemos igual numero de latentes como clases para clasificar\n    whiten=True,#Mejora la estabilidad eliminando la covarianza entre las variables inducidas Z\n    q_diag=True,#Asume covarianza diagonal para mejorar el rendimiento\n)\n\n# Evitamos que se entrene la vanrianza del ruido\nset_trainable(m.kernel.kernels[1].variance, False)\n# Evitamos que se modifiquen los puntos Z inducidos\nset_trainable(m.inducing_variable, False)\nprint_summary(m, fmt=\"notebook\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:28:53.327905Z","iopub.execute_input":"2024-10-03T00:28:53.329001Z","iopub.status.idle":"2024-10-03T00:28:56.454175Z","shell.execute_reply.started":"2024-10-03T00:28:53.328956Z","shell.execute_reply":"2024-10-03T00:28:56.453226Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table>\n<thead>\n<tr><th>name                               </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value                </th></tr>\n</thead>\n<tbody>\n<tr><td>SVGP.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0                  </td></tr>\n<tr><td>SVGP.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0                  </td></tr>\n<tr><td>SVGP.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>False      </td><td>()         </td><td>float64</td><td>0.009999999999999998 </td></tr>\n<tr><td>SVGP.likelihood.invlink.epsilon    </td><td>Parameter</td><td>Sigmoid    </td><td>Beta   </td><td>False      </td><td>()         </td><td>float64</td><td>0.0010000000000000005</td></tr>\n<tr><td>SVGP.inducing_variable.Z           </td><td>Parameter</td><td>Identity   </td><td>       </td><td>False      </td><td>(2000, 784)</td><td>float64</td><td>[[0., 0., 0....      </td></tr>\n<tr><td>SVGP.q_mu                          </td><td>Parameter</td><td>Identity   </td><td>       </td><td>True       </td><td>(2000, 10) </td><td>float64</td><td>[[0., 0., 0....      </td></tr>\n<tr><td>SVGP.q_sqrt                        </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>(2000, 10) </td><td>float64</td><td>[[1., 1., 1....      </td></tr>\n</tbody>\n</table>"},"metadata":{}}]},{"cell_type":"code","source":"opt = gpflow.optimizers.Scipy() #Llamamos Scipy para la optimizacion\n\n#Entrenamos\nopt_logs = opt.minimize(\n    m.training_loss_closure(data_train),#Minimizando el loss\n    m.trainable_variables,\n    options=dict(maxiter=reduce_in_tests(1000)),#definimos un maximo de 1000 iteraciones para evitar sobrecarga computacional\n)\nprint_summary(m, fmt=\"notebook\")","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:28:59.509099Z","iopub.execute_input":"2024-10-03T00:28:59.509991Z","iopub.status.idle":"2024-10-03T01:01:49.051126Z","shell.execute_reply.started":"2024-10-03T00:28:59.509950Z","shell.execute_reply":"2024-10-03T01:01:49.050152Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table>\n<thead>\n<tr><th>name                               </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value                                     </th></tr>\n</thead>\n<tbody>\n<tr><td>SVGP.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>57.20021                                  </td></tr>\n<tr><td>SVGP.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>52.42083                                  </td></tr>\n<tr><td>SVGP.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>False      </td><td>()         </td><td>float64</td><td>0.009999999999999998                      </td></tr>\n<tr><td>SVGP.likelihood.invlink.epsilon    </td><td>Parameter</td><td>Sigmoid    </td><td>Beta   </td><td>False      </td><td>()         </td><td>float64</td><td>0.0010000000000000005                     </td></tr>\n<tr><td>SVGP.inducing_variable.Z           </td><td>Parameter</td><td>Identity   </td><td>       </td><td>False      </td><td>(2000, 784)</td><td>float64</td><td>[[0., 0., 0....                           </td></tr>\n<tr><td>SVGP.q_mu                          </td><td>Parameter</td><td>Identity   </td><td>       </td><td>True       </td><td>(2000, 10) </td><td>float64</td><td>[[-0.85056459, -0.78498826, -0.30280321...</td></tr>\n<tr><td>SVGP.q_sqrt                        </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>(2000, 10) </td><td>float64</td><td>[[0.00358828, 0.00782771, 0.00312437...   </td></tr>\n</tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Prediccion usando los datos de prueba**","metadata":{}},{"cell_type":"code","source":"prediction  = m.predict_y(x_test_64)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:23:08.519193Z","iopub.status.idle":"2024-10-03T00:23:08.519537Z","shell.execute_reply.started":"2024-10-03T00:23:08.519370Z","shell.execute_reply":"2024-10-03T00:23:08.519387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(prediction[0].shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:23:08.520445Z","iopub.status.idle":"2024-10-03T00:23:08.520762Z","shell.execute_reply.started":"2024-10-03T00:23:08.520598Z","shell.execute_reply":"2024-10-03T00:23:08.520615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Verificamos el accuracy de las predicciones**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Predicciones (one-hot encoded) y etiquetas reales\npredicciones_one_hot = prediction[0]  #Prediccones en formato one-hot encoding que salen directamente del modelo\netiquetas_reales = y_test_64  # Etiquetas reales\n\n# Convertir one-hot encoded a etiquetas discretas (índices de clases)\npredicciones_labels = np.argmax(predicciones_one_hot, axis=1)\n\n# Calcular precisión\nprecision = accuracy_score(etiquetas_reales, predicciones_labels)\nprint(f'Precisión: {precision * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:23:08.521951Z","iopub.status.idle":"2024-10-03T00:23:08.522309Z","shell.execute_reply.started":"2024-10-03T00:23:08.522134Z","shell.execute_reply":"2024-10-03T00:23:08.522152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Graficamos una matriz de confusion**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n\n\n# Generar matriz de confusión normalizada\ncm = confusion_matrix(etiquetas_reales, predicciones_labels,normalize=\"true\")\n\n# Visualizamos la matriz de confusion\ndisp=ConfusionMatrixDisplay(confusion_matrix=cm)\nfig, ax = plt.subplots(figsize=(8,8))\ndisp.plot(ax=ax)","metadata":{"execution":{"iopub.status.busy":"2024-10-03T00:23:08.523679Z","iopub.status.idle":"2024-10-03T00:23:08.524184Z","shell.execute_reply.started":"2024-10-03T00:23:08.523849Z","shell.execute_reply":"2024-10-03T00:23:08.523867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Discusion de las ventajas y desventajas comparado con un autoencoder variacional**","metadata":{}},{"cell_type":"markdown","source":"- Los modelos gp tienen la gran desventaja de ser muy exigentes en cuanto a recursos, tratar de entrenar el sparse gp con los 55000 datos de Fashion Mnist fallaba por llenado de la RAM. Sin embargo, se ve su potencia en el hecho de que alcanzan un resultado más que aceptable entrenando con un quinto de los datos que se usaron para entrenar un clasificador convolucional o variacional.\n- Practicamente sin tunear la mayoria de hiperparamtros y basados en una configuracion estandar del sparse gp, se logro clasificar la mayoria de las clases con mas del 80% de precision usando muchos menos datos. Eso muestra el gran potencial que tiene el modelo. Buscando aumentar el número de datos de entrada a uno más grande que no colapse por falta de memoria, y jugando con los hiperparametros, seguramente se podría conseguir un resultado similar o superior al que logra un modelo variacional.\n- Tambien cabe recordar lo sensible que es el modelo variacional a la regularización del espacio latente, lo que suele llevar a que explote o se desvanezca el gradiente en el entrenamiento. El modelo gp no tiene ese problema al no tener que regularizar un espacio latente que se parezca a una funcion gaussiana normal.","metadata":{}},{"cell_type":"markdown","source":"## Ejercicio\n\n- Describa el modelo y la optimización de los GPR, GPC, VGP, SGPR, y SVGP.\n\n- Discuta los métodos de optimización que utiliza GPFlow con scipy y TensorFlow.\n\n- Implemente un clasificador multiclase, para la base de datos fashionMnist, utilizando un Sparse GP implementado con GPflow y optimizador de TensorFlow. (ver [https://gpflow.github.io/GPflow/develop/getting_started.html](https://gpflow.github.io/GPflow/develop/getting_started.html))\n\n- Discuta las ventajas y desventajas de un clasificador tipo autoencoder variacional vs un modelo basado en GP y GPflow.","metadata":{"id":"W80fivK07hWc"}}]}